{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a352ba4-8967-48bc-b3c0-52203bf19c04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "main_df = pd.read_csv('2023_Q3.2_AllData_Before_20231215.csv', header=0, index_col=0, low_memory=False).reset_index(drop=True)\n",
    "print(\"Original shape: \")\n",
    "print(main_df.shape)\n",
    "main_df = main_df.drop_duplicates()\n",
    "\n",
    "dropnas_df = main_df.dropna(axis=1, how=\"all\")\n",
    "dropnas_df = dropnas_df.dropna(subset=['Value'])\n",
    "dropnas_df = dropnas_df.drop(\n",
    "print(\"New shape after dropna: \")\n",
    "print(dropnas_df.shape)\n",
    "\n",
    "droplist = ['SeriesID','ReleaseStatus', 'ReleaseName', 'isDSDSeries', 'Time_Detail', \n",
    "            'Source', 'SeriesObservationCount', 'UpperBound', 'SeriesDescription',\n",
    "            'LowerBound', 'ObservationID', 'Observation Status', 'FootNote', 'Reporting Type', \n",
    "            'GeoAreaCode', 'Cities'\n",
    "           ]\n",
    "\n",
    "df = dropnas_df.drop(droplist, axis=1).drop_duplicates()\n",
    "print(\"Different after dropping superfluous fields? shape: \")\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "discriminator_df = df.drop(['ID', 'Goal', 'Target', 'Value', 'ValueType', 'TimePeriod', 'BasePeriod', 'GeoAreaName', 'Units'], axis=1)\n",
    "# discriminator_df['discriminator_combo'] = discriminator_df.apply(lambda row: tuple(row.dropna()), axis=1)\n",
    "discriminator_df['discriminator_combo'] = discriminator_df.apply(lambda row: tuple((col, val) for col, val in row.dropna().items()), axis=1)\n",
    "df['discriminator_combo'] = discriminator_df['discriminator_combo']\n",
    "print(\"Discriminator DF shape: \")\n",
    "print(discriminator_df.shape)\n",
    "\n",
    "conditioning_droplist = ['ID', 'Goal', 'Target', 'Indicator', 'SeriesCode', 'ValueType', 'BasePeriod', 'Age', 'Location', 'Sex', 'Units', 'Level/Status', 'Education level', 'Type of product', 'Name of international institution',\n",
    "                        'Type of occupation', 'Type of skill', 'Mode of transportation', 'Name of non-communicable disease', 'Type of speed', 'Migratory status', 'Disability status', 'IHR Capacity', 'Quantile', 'Activity',\n",
    "                         'Policy Domains', 'Policy instruments', 'Sampling Stations', 'Type of waste treatment', 'Grounds of discrimination', 'Parliamentary committees', 'Cause of death', 'Substance use disorders',\n",
    "                        'Deviation Level', 'Frequency of Chlorophyll-a concentration', 'Food Waste Sector', 'Fiscal intervention stage', 'Level of requirement', 'Type of support', 'Report Ordinal', 'Counterpart', 'Government_Name', \n",
    "                        'Severity of price levels', 'Level_of_government', 'Type of renewable technology', 'Population Group', 'Service Attribute', 'Land cover', 'Bioclimatic belt', 'Illicit Financial Flows', 'Nutrient Loading',\n",
    "                        'Type of OFDI scheme','Nature', ]\n",
    "unconditioned_df = df.drop(conditioning_droplist, axis=1)\n",
    "print(\"Final shape before pivot: \")\n",
    "print(unconditioned_df.shape)\n",
    "\n",
    "conditioned_df = unconditioned_df.pivot_table(index=['GeoAreaName', 'TimePeriod'],\n",
    "                                             columns='discriminator_combo',\n",
    "                                             values='Value',\n",
    "                                             aggfunc='mean').reset_index()\n",
    "\n",
    "print(\"Total number of values in conditioned DF: \")\n",
    "print(conditioned_df.count().sum()) \n",
    "\n",
    "conditioned_df.to_csv(\"2d SDG Dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b629082f-8d65-4917-9cea-8a6e22e48b75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unconditioned_df[pd.to_numeric(unconditioned_df['Value'], errors='coerce').isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06725505-8b13-46c3-872e-a954c82397cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conditioned_df.count().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5526e318-b908-4731-8d18-b2b88909b1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_df.Value.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3d2a0e-a59f-42ba-813a-3e800bf169b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conditioned_df.count().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5379897-59c7-4b11-af5b-e3f3f1733de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unconditioned_df[unconditioned_df.discriminator_combo == (\"15.4.2\", \"ER_MTN_GRNCVI\", \"ARTIFICIAL\", \"NIVAL\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aee55e-d71e-4b61-97dc-edb98c6b29a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "df.Value.isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
