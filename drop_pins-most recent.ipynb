{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37d7c927-5daf-454a-9848-4cc6bf6e6bf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import rapidjson\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44fbac5-4d83-4b39-bf40-e3c6d82f94d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "node_path = \"np_node-template.csv\"\n",
    "tag_path = \"np_tag-template.csv\"\n",
    "os.chmod(node_path, 0o777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76b2e0b0-3ea3-4275-9cea-95c9dff95120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geoinfo_df = pd.read_csv('GeoLocationInfo.csv')\n",
    "node_df = pd.read_csv(node_path)\n",
    "tag_df = pd.read_csv(tag_path)\n",
    "data =  pd.read_csv(\"2d SDG Dataset.csv\", header=0, low_memory=False).reset_index(drop=True)\n",
    "indicators_with_index = ['GeoAreaCode', 'GeoAreaName', 'TimePeriod', '1.1.1', '1.4.1', '6.1.1',\n",
    "             '13.1.1','13.1.2','17.1.1', '17.1.2']\n",
    "subset_columns = []\n",
    "\n",
    "# Check for regular string columns\n",
    "subset_columns += [col for col in data.columns if col in ['GeoAreaCode', 'GeoAreaName', 'TimePeriod']]\n",
    "\n",
    "# Check for JSON columns\n",
    "for col in data.columns:\n",
    "    if col not in ['GeoAreaCode', 'TimePeriod']:\n",
    "        try:\n",
    "            col_json = rapidjson.loads(col)\n",
    "            if col_json.get(\"Indicator\") in indicators_with_index:\n",
    "                subset_columns.append(col)\n",
    "        except rapidjson.JSONDecodeError:\n",
    "            continue\n",
    "# subset_columns = [col for col in data.columns if any(indicator in col for indicator in indicators_with_index)]\n",
    "subset = data[subset_columns]\n",
    "# subset.drop(subset.columns[[9,10,11,12,13]], axis=1, inplace=True)\n",
    "\n",
    "timeperiods = [2000, 2005, 2010, 2015, 2020]\n",
    "drop_cols = ['{\"Indicator\": \"13.1.1\", \"SeriesCode\": \"VC_DSR_MMHN\"}','{\"Indicator\": \"13.1.1\", \"SeriesCode\": \"VC_DSR_MORT\"}','{\"Indicator\": \"13.1.1\", \"SeriesCode\": \"VC_DSR_PDAN\"}',\n",
    "             '{\"Indicator\": \"13.1.1\", \"SeriesCode\": \"VC_DSR_PDLN\"}','{\"Indicator\": \"13.1.1\", \"SeriesCode\": \"VC_DSR_PDYN\"}','{\"Indicator\": \"17.1.1\", \"SeriesCode\": \"GR_G14_XDC\"}',\n",
    "             '{\"Indicator\": \"13.1.1\", \"SeriesCode\": \"VC_DSR_AFFCT\"}','{\"Indicator\": \"13.1.1\", \"SeriesCode\": \"VC_DSR_DAFF\"}', '{\"Indicator\": \"13.1.1\", \"SeriesCode\": \"VC_DSR_IJILN\"}',\n",
    "             '{\"Indicator\": \"13.1.1\", \"SeriesCode\": \"VC_DSR_MISS\"}','{\"Indicator\": \"13.1.1\", \"SeriesCode\": \"VC_DSR_MTMP\"}']\n",
    "subset = subset[subset['TimePeriod'].isin(timeperiods)]\n",
    "subset = subset.drop(drop_cols, axis=1)\n",
    "subset_to_scale = subset.iloc[:, 3:]\n",
    "# min_values = subset_to_scale.min()\n",
    "# max_values = subset_to_scale.max()\n",
    "scaled_subset = subset_to_scale/100\n",
    "scaled_df = pd.concat([subset.iloc[:, :3], scaled_subset], axis=1)\n",
    "valid_geo_area_names = geoinfo_df['GeoAreaName'].unique()\n",
    "scaled_df = scaled_df[scaled_df['GeoAreaName'].isin(valid_geo_area_names)]\n",
    "mask = scaled_df.apply(lambda row: any(isinstance(cell, str) or (isinstance(cell, (int, float)) and cell > 100) for cell in row), axis=1)\n",
    "scaled_df = scaled_df[mask]\n",
    "scaled_df = scaled_df.fillna(0)\n",
    "# scaled_df = scaled_df[scaled_df.GeoAreaName == 'Kenya']\n",
    "scaled_df.drop(scaled_df.columns[[1]], axis=1, inplace=True)\n",
    "scaled_df.to_csv('subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a51307bb-9d08-4237-875f-aaa241301998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 57s\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "node_df = pd.read_csv(node_path)\n",
    "tag_df = pd.read_csv(tag_path)\n",
    "previous_geo_code = \"\"\n",
    "previous_time_period = \"\"\n",
    "previous_indicator = \"\"\n",
    "previous_series = \"\"\n",
    "ring_location = -115\n",
    "series_ring_location = 0\n",
    "petal_location = -15\n",
    "num_goals = 4\n",
    "data_id=1\n",
    "id_iter=1\n",
    "\n",
    "for idx, row in scaled_df.iterrows():\n",
    "    rod_location = -180\n",
    "    new_pin = node_df.iloc[0].copy()\n",
    "    new_tag = tag_df.iloc[0].copy()\n",
    "    \n",
    "    for column, value in row.items():\n",
    "        \n",
    "        if column == 'GeoAreaCode':\n",
    "            if row.GeoAreaCode == previous_geo_code:\n",
    "                ring_location += 20\n",
    "            else:\n",
    "                ring_location = -115\n",
    "                pin_id = id_iter\n",
    "                id_iter+=1\n",
    "                geoinfo = geoinfo_df[geoinfo_df.GeoAreaCode == row.GeoAreaCode]\n",
    "                # new_pin[[\"np_node_id\", \"np_data_id\",  \"np_tag_id\", \"record_id\"]] = int(pin_id)\n",
    "                new_pin[[\"np_node_id\", \"np_tag_id\", \"record_id\"]] = pin_id\n",
    "                new_pin['np_table_id'] = 1\n",
    "                new_pin['translate_x'] = geoinfo['translate_x'].values[0]\n",
    "                new_pin['translate_y'] = geoinfo['translate_y'].values[0]\n",
    "                new_pin['np_geometry_id'] = 19\n",
    "                new_pin['np_topo_id'] = 6\n",
    "                new_tag[[\"np_tag_id\", \"record_id\"]] = pin_id\n",
    "                new_tag[\"table_id\"] = 1\n",
    "                new_tag[\"title\"] =  geoinfo_df[geoinfo_df.GeoAreaCode == row.GeoAreaCode].GeoAreaName.reset_index(drop=True).iloc[0]\n",
    "                new_tag[\"description\"] = 'Country'\n",
    "                node_df = pd.concat([node_df, pd.DataFrame(new_pin).T], ignore_index=True)\n",
    "                tag_df = pd.concat([tag_df, pd.DataFrame(new_tag).T], ignore_index=True)\n",
    "                previous_geo_code = row.GeoAreaCode\n",
    "\n",
    "        \n",
    "        elif column == 'TimePeriod':\n",
    "            ring_id = id_iter\n",
    "            id_iter+=1\n",
    "            # print(str(row.GeoAreaCode)+str(row.TimePeriod))\n",
    "            new_year_ring = node_df.iloc[1].copy()\n",
    "            new_year_tag = tag_df.iloc[0].copy()\n",
    "            # new_year_ring[[\"np_node_id\", \"np_data_id\",  \"np_tag_id\", \"record_id\"]] = int(ring_id)\n",
    "            new_year_ring[[\"np_node_id\", \"np_tag_id\", \"record_id\"]] = ring_id\n",
    "            new_year_ring[\"parent_id\"] = pin_id\n",
    "            new_year_ring[\"branch_level\"]=2\n",
    "            new_year_ring[\"translate_x\"] = ring_location\n",
    "            new_year_ring[['scale_x', 'scale_y', 'scale_z']] = .5\n",
    "            new_year_ring['np_table_id'] = 1\n",
    "            new_year_tag[[\"np_tag_id\", \"record_id\"]] = ring_id\n",
    "            new_year_tag[\"table_id\"] = 1\n",
    "            new_year_tag[\"title\"] = row.TimePeriod\n",
    "            new_year_tag[\"description\"] = \"Year\"\n",
    "            node_df = pd.concat([node_df, pd.DataFrame(new_year_ring).T], ignore_index=True)\n",
    "            tag_df = pd.concat([tag_df, pd.DataFrame(new_year_tag).T], ignore_index=True)\n",
    "            previous_time_period = row.TimePeriod\n",
    "        else:\n",
    "            discriminator = rapidjson.loads(column)\n",
    "            current_indicator = discriminator[\"Indicator\"]\n",
    "            current_series = discriminator[\"SeriesCode\"]\n",
    "            if current_indicator == previous_indicator:\n",
    "                \n",
    "                series_ring_location -= 5\n",
    "                if current_series == previous_series:\n",
    "                    petal_id=id_iter\n",
    "                    id_iter += 1\n",
    "                    petal_tag_title = \"\"\n",
    "                    for disc_type, type_value in discriminator.items():\n",
    "                        if disc_type not in ['Indicator', 'SeriesCode']:\n",
    "                            petal_tag_title += type_value\n",
    "                    new_subseries_petal = node_df.iloc[1].copy()\n",
    "                    new_subseries_petal_tag = tag_df.iloc[0].copy()\n",
    "                    new_subseries_petal[[\"np_node_id\", \"np_data_id\",  \"np_tag_id\", \"record_id\"]] = int(petal_id)\n",
    "                    # new_subseries_petal[[\"np_node_id\", \"np_tag_id\", \"record_id\"]] = petal_id\n",
    "                    new_subseries_petal[\"parent_id\"] = series_id\n",
    "                    new_subseries_petal[\"branch_level\"]=5\n",
    "                    new_subseries_petal[\"translate_x\"] = petal_location\n",
    "                    new_subseries_petal[['scale_x', 'scale_y', 'scale_z']] = 1\n",
    "                    new_subseries_petal[\"np_geometry_id\"] = 3\n",
    "                    if value == 0 :\n",
    "                        new_subseries_petal[\"np_geometry_id\"] = 2\n",
    "                        new_subseries_petal[\"np_topo_id\"] = 10\n",
    "                    else:\n",
    "                        new_subseries_petal[\"np_geometry_id\"] = 3\n",
    "                        new_subseries_petal[\"np_topo_id\"] = 2\n",
    "                    new_subseries_petal['np_table_id'] = 1\n",
    "                    new_subseries_petal[['scale_x','scale_y','scale_z']] = 1+.5*value\n",
    "                    new_subseries_petal_tag[[\"np_tag_id\", \"record_id\"]] = petal_id\n",
    "                    new_subseries_petal_tag[\"table_id\"] = 1\n",
    "                    new_subseries_petal_tag[\"title\"] = petal_tag_title\n",
    "                    new_subseries_petal_tag[\"description\"] = \"Series sub\"\n",
    "                    node_df = pd.concat([node_df, pd.DataFrame(new_subseries_petal).T], ignore_index=True)\n",
    "                    tag_df = pd.concat([tag_df, pd.DataFrame(new_subseries_petal_tag).T], ignore_index=True)\n",
    "                    petal_location += 30\n",
    "                    previous_series = current_series\n",
    "                else:\n",
    "                    petal_location = -15\n",
    "                    series_id=id_iter\n",
    "                    id_iter += 1\n",
    "                    petal_id=id_iter\n",
    "                    id_iter += 1\n",
    "                    new_series_ring = node_df.iloc[1].copy()\n",
    "                    new_series_tag = tag_df.iloc[0].copy()\n",
    "                    new_series_ring[[\"np_node_id\", \"np_data_id\",  \"np_tag_id\", \"record_id\"]] = int(series_id)\n",
    "                    new_series_ring[[\"np_node_id\", \"np_tag_id\", \"record_id\"]] = series_id\n",
    "                    new_series_ring[\"parent_id\"] = indicator_id\n",
    "                    new_series_ring[\"branch_level\"]=4\n",
    "                    new_series_ring[\"translate_x\"] = series_ring_location\n",
    "                    new_series_ring[['scale_x', 'scale_y', 'scale_z']] = 1\n",
    "                    new_series_ring['np_table_id'] = 1\n",
    "                    if value == 0:\n",
    "                        new_series_ring[\"np_geometry_id\"] = 6\n",
    "                        new_series_ring[\"np_topo_id\"] = 11\n",
    "                    else:\n",
    "                        new_series_ring[\"np_topo_id\"] = 7\n",
    "                        new_series_ring[\"np_topo_id\"] = 3\n",
    "                    new_series_ring[['scale_x','scale_y','scale_z']] = 1+.5*value\n",
    "                    new_series_tag[[\"np_tag_id\", \"record_id\"]] = series_id\n",
    "                    new_series_tag[\"table_id\"] = 1\n",
    "                    new_series_tag[\"title\"] = current_series\n",
    "                    new_series_tag[\"description\"] = \"Series Code\"\n",
    "                    node_df = pd.concat([node_df, pd.DataFrame(new_series_ring).T], ignore_index=True)\n",
    "                    tag_df = pd.concat([tag_df, pd.DataFrame(new_series_tag).T], ignore_index=True)\n",
    "                    # petal_tag_title = \"\"\n",
    "                    # for disc_type, type_value in discriminator.items():\n",
    "                    #     if disc_type not in ['Indicator', 'SeriesCode']:\n",
    "                    #         petal_tag_title += type_value\n",
    "                    # new_subseries_petal = node_df.iloc[1].copy()\n",
    "                    # new_subseries_petal_tag = tag_df.iloc[0].copy()\n",
    "                    # # new_series_petal[[\"np_node_id\", \"np_data_id\",  \"np_tag_id\", \"record_id\"]] = int(petal_id)\n",
    "                    # new_subseries_petal[[\"np_node_id\", \"np_tag_id\", \"record_id\"]] = petal_id\n",
    "                    # new_subseries_petal[\"parent_id\"] = series_id\n",
    "                    # new_subseries_petal[\"branch_level\"]=5\n",
    "                    # new_subseries_petal[\"translate_x\"] = petal_location\n",
    "                    # new_subseries_petal[['scale_x', 'scale_y', 'scale_z']] = 1\n",
    "                    # new_subseries_petal[\"np_geometry_id\"] = 3\n",
    "                    # if value == 0 :\n",
    "                    #     new_subseries_petal[\"np_topo_id\"] = 2\n",
    "                    # else:\n",
    "                    #     new_subseries_petal[\"np_topo_id\"] = 3\n",
    "                    # new_subseries_petal['np_table_id'] = 1\n",
    "                    # new_subseries_petal[['scale_x','scale_y','scale_z']] = 1+.5*value\n",
    "                    # new_subseries_petal_tag[[\"np_tag_id\", \"record_id\"]] = petal_id\n",
    "                    # new_subseries_petal_tag[\"table_id\"] = 1\n",
    "                    # new_subseries_petal_tag[\"title\"] = petal_tag_title\n",
    "                    # new_subseries_petal_tag[\"description\"] = \"Series sub\"\n",
    "                    # node_df = pd.concat([node_df, pd.DataFrame(new_subseries_petal).T], ignore_index=True)\n",
    "                    # tag_df = pd.concat([tag_df, pd.DataFrame(new_subseries_petal_tag).T], ignore_index=True)\n",
    "                    # petal_location += 30\n",
    "                    previous_series = current_series\n",
    "            else:\n",
    "                indicator_id=id_iter\n",
    "                id_iter+=1\n",
    "                series_ring_location = 0\n",
    "                new_indicator_bar = node_df.iloc[1].copy()\n",
    "                new_indicator_tag = tag_df.iloc[0].copy()\n",
    "                new_indicator_bar[[\"np_node_id\", \"np_data_id\",  \"np_tag_id\", \"record_id\"]] = int(indicator_id)\n",
    "                # new_indicator_bar[[\"np_node_id\", \"np_tag_id\", \"record_id\"]] = indicator_id\n",
    "                new_indicator_bar[\"parent_id\"] = ring_id\n",
    "                new_indicator_bar[\"branch_level\"]=3\n",
    "                new_indicator_bar[\"translate_x\"] = rod_location\n",
    "                rod_location += 40\n",
    "                new_indicator_bar[\"np_geometry_id\"] = 19\n",
    "                new_indicator_bar[\"np_topo_id\"] = 6\n",
    "                new_indicator_bar['np_table_id'] = 1\n",
    "                new_indicator_tag[\"table_id\"] = 1\n",
    "                new_indicator_tag[[\"np_tag_id\", \"record_id\"]] = indicator_id\n",
    "                new_indicator_tag[\"title\"] = current_indicator\n",
    "                new_indicator_tag[\"description\"] = \"Indicator\"\n",
    "                node_df = pd.concat([node_df, pd.DataFrame(new_indicator_bar).T], ignore_index=True)\n",
    "                tag_df = pd.concat([tag_df, pd.DataFrame(new_indicator_tag).T], ignore_index=True)\n",
    "                previous_indicator = current_indicator\n",
    "                series_id=id_iter\n",
    "                id_iter += 1\n",
    "                new_series_ring = node_df.iloc[1].copy()\n",
    "                new_series_tag = tag_df.iloc[0].copy()\n",
    "                new_series_ring[[\"np_node_id\", \"np_data_id\",  \"np_tag_id\", \"record_id\"]] = int(series_id)\n",
    "                # new_series_ring[[\"np_node_id\", \"np_tag_id\", \"record_id\"]] = series_id\n",
    "                new_series_ring[\"parent_id\"] = indicator_id\n",
    "                new_series_ring[\"branch_level\"]=4\n",
    "                new_series_ring[\"translate_x\"] = series_ring_location\n",
    "                new_series_ring[['scale_x', 'scale_y', 'scale_z']] = 1\n",
    "                new_series_ring['np_table_id'] = 1\n",
    "                if value == 0:\n",
    "                    new_series_ring[\"np_geometry_id\"] = 6\n",
    "                    new_series_ring[\"np_topo_id\"] = 11\n",
    "                else:\n",
    "                    new_series_ring[\"np_topo_id\"] = 7\n",
    "                    new_series_ring[\"np_topo_id\"] = 3\n",
    "                new_series_ring[['scale_x','scale_y','scale_z']] = 1+.5*value\n",
    "                new_series_tag[[\"np_tag_id\", \"record_id\"]] = series_id\n",
    "                new_series_tag[\"table_id\"] = 1\n",
    "                new_series_tag[\"title\"] = current_series\n",
    "                new_series_tag[\"description\"] = \"Series Code\"\n",
    "                node_df = pd.concat([node_df, pd.DataFrame(new_series_ring).T], ignore_index=True)\n",
    "                tag_df = pd.concat([tag_df, pd.DataFrame(new_series_tag).T], ignore_index=True)\n",
    "                previous_series=current_series\n",
    "                \n",
    "node_df = node_df.iloc[3:]\n",
    "tag_df = tag_df.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68360eac-e032-4cfc-9428-d05b699d6eef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "node_ints = ['np_node_id','type','np_data_id','selected','parent_id','branch_level','child_id','np_tag_id','np_palette_id','np_ch_in_id','np_ch_out_id','ch_sync_time','np_palette_id_alt','np_color_id_alt',\n",
    "            'np_material_id','np_geometry_id', 'np_color_id', 'color_fade','np_texture_id','hide','freeze','np_topo_id','subspace','trigger_hi_x','trigger_hi_y','trigger_hi_z','trigger_lo_x','trigger_lo_y','trigger_lo_z', \n",
    "            'proximity_x','proximity_y','proximity_z','proximity_mode_x','proximity_mode_y','proximity_mode_z','segments_x','segments_y','segments_z','tag_mode','np_format_id','np_table_id','size']\n",
    "\n",
    "node_df[node_ints] = node_df[node_ints].astype(int)\n",
    "node_df['record_id'] = node_df['record_id'].astype(np.int64)\n",
    "node_df.to_csv(\"C:\\\\Users\\\\jarrod.clark\\\\Desktop\\\\gaia_2024-02-11_app\\\\User\\\\Prototypes\\\\2024-04-04\\\\proto-20240404T125841\\\\csv\\\\proto-20240404T125841_np_node.csv\",mode='w', index=False)\n",
    "\n",
    "tag_df[[\"np_tag_id\", \"record_id\"]] = tag_df[[\"np_tag_id\", \"record_id\"]].astype(int)\n",
    "tag_df.to_csv(\"C:\\\\Users\\\\jarrod.clark\\\\Desktop\\\\gaia_2024-02-11_app\\\\User\\\\Prototypes\\\\2024-04-04\\\\proto-20240404T125841\\\\csv\\\\proto-20240404T125841_np_tag.csv\",mode='w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a3a22-2cc5-4b90-803b-d91e8b0405b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
